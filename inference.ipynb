{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXWqzF5L8Fft"
      },
      "source": [
        "Evet Bakalım Beauty Analysis Çalışalım biraz. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XxCixf6m8Ffz"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io as imageio\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "AEEf8S-f8Ff1"
      },
      "outputs": [],
      "source": [
        "mar=cv2.imread(\"./rl1.PNG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzvvvx088Ff2"
      },
      "outputs": [],
      "source": [
        "imageio.imshow(mar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4_LhjwE8Ff4"
      },
      "outputs": [],
      "source": [
        "rgb=cv2.cvtColor(mar,cv2.COLOR_BGR2RGB)\n",
        "imageio.imshow(rgb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ccYIPUJ9R2R",
        "outputId": "679ab6ff-f1a1-468f-bb50-7a326ceb1726"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-24 14:54:04--  https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 341406 (333K) [text/plain]\n",
            "Saving to: ‘haarcascade_eye.xml’\n",
            "\n",
            "\rhaarcascade_eye.xml   0%[                    ]       0  --.-KB/s               \rhaarcascade_eye.xml 100%[===================>] 333.40K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-02-24 14:54:04 (95.5 MB/s) - ‘haarcascade_eye.xml’ saved [341406/341406]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "qCfHR8mu8Ff5"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "#detector = dlib.get_frontal_face_detector()\n",
        "eyedetect=cv2.CascadeClassifier('./haarcascade_eye.xml')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "f1wp3FaM8Ff5"
      },
      "outputs": [],
      "source": [
        "geteye=eyedetect.detectMultiScale(rgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4uMrBej8Ff6",
        "outputId": "00d664ed-e831-4150-c8c5-26156a8bc4c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[199,   4,  26,  26],\n",
              "       [343, 214,  50,  50]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "geteye"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tsiRhbL8Ff7"
      },
      "outputs": [],
      "source": [
        "gozler=[]\n",
        "for (x,y,w,h) in geteye:\n",
        "    gozler.append(rgb[y:y+h, x:x+w])\n",
        "imageio.imshow(gozler[0])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVOAJoGv8Ff8"
      },
      "outputs": [],
      "source": [
        "imageio.imshow(gozler[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "left_eye = gozler[0];\n",
        "right_eye = gozler[1];"
      ],
      "metadata": {
        "id": "IFGtNm-9Ohwp"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "import albumentations as A\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from skimage import io\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "onJb_ukm-lsN"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channels = 1,num_classes = 10):\n",
        "    super(CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size = (3,3), stride=(1,1), padding=(1,1)) # same convolution as output size will be same\n",
        "    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.fc1 = nn.Linear(4096,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = x.reshape(x.shape[0],-1)\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "CLjIEarJAlH9"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 64*64;\n",
        "num_classes = 2;\n",
        "\n",
        "model = CNN(input_size,num_classes)\n",
        "model.load_state_dict(torch.load('model_95.pt',map_location=torch.device('cpu')));\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y--PCpuZNVVN",
        "outputId": "671c7d84-f4bb-4bfd-b28e-8f1ad434a5f0"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=4096, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                 transforms.Resize(64),\n",
        "                                 transforms.Grayscale(num_output_channels=1),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize(mean=[0.5],std=[0.5],inplace=True)\n",
        "                                ]);"
      ],
      "metadata": {
        "id": "-8ZkTLUJN-HO"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageio.imshow(right_eye)"
      ],
      "metadata": {
        "id": "M39DDrByOqgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "PIL_image = Image.fromarray(right_eye.astype('uint8'), 'RGB') #convery numpy to PIL image\n",
        "\n",
        "t_img = transform(PIL_image).squeeze(); # squeeze used to change 1,64,64 to 64,64\n",
        "imageio.imshow(t_img.numpy()) # convert back to numpy to display"
      ],
      "metadata": {
        "id": "ecMfeutPOwhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = transform(PIL_image);\n",
        "img = img[None]\n",
        "temp = model(img)\n"
      ],
      "metadata": {
        "id": "ZH07XEuOPaBt"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja7GXZlPhOxF",
        "outputId": "11144f6e-6503-4492-8e1a-7078d50bc5ce"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.0020,  1.1284]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2;\n",
        "import numpy as np;\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "#detector = dlib.get_frontal_face_detector()\n",
        "eyedetect=cv2.CascadeClassifier('./haarcascade_eye.xml')\n",
        "\n",
        "\n",
        "\n",
        "# font\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "# org\n",
        "org = (50, 50)\n",
        "# fontScale\n",
        "fontScale = 1\n",
        "# Blue color in BGR\n",
        "color = (255, 0, 0)\n",
        "# Line thickness of 2 px\n",
        "thickness = 2\n",
        "\n",
        "  \n",
        "# define a video capture object\n",
        "vid = cv2.VideoCapture('')\n",
        "  \n",
        "while(True):\n",
        "      \n",
        "    # Capture the video frame\n",
        "    # by frame\n",
        "    #ret, frame = vid.read()\n",
        "    frame=cv2.imread(\"./rl1.PNG\")\n",
        "\n",
        "    if(frame.all() != None):\n",
        "\n",
        "      geteye=eyedetect.detectMultiScale(frame)\n",
        "      \n",
        "      eyes=[]\n",
        "      for (x,y,w,h) in geteye:\n",
        "          eyes.append(rgb[y:y+h, x:x+w])\n",
        "      \n",
        "      imageio.imshow(eyes[1])    \n",
        "      img = eyes[1]\n",
        "      img = Image.fromarray(img.astype('uint8'), 'RGB')\n",
        "      img = transform(img);\n",
        "      img = img[None]\n",
        "      scores = model(img)\n",
        "\n",
        "      print(scores)\n",
        "      prediction = scores[0].argmax()\n",
        "\n",
        "      frame = cv2.putText(frame, str(prediction), org, font, fontScale, color, thickness, cv2.LINE_AA)    \n",
        "    \n",
        "    #cv2.imshow('frame', frame)\n",
        "    cv2_imshow(frame);\n",
        "      \n",
        "    break;\n",
        "    # the 'q' button is set as the\n",
        "    # quitting button you may use any\n",
        "    # desired button of your choice\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "  \n",
        "# After the loop release the cap object\n",
        "vid.release()\n",
        "# Destroy all the windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "uoWW_7NQRALQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2;\n",
        "import numpy as np;\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "#detector = dlib.get_frontal_face_detector()\n",
        "eyedetect=cv2.CascadeClassifier('./haarcascade_eye.xml')\n",
        "\n",
        "\n",
        "\n",
        "# font\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "# org\n",
        "org = (50, 50)\n",
        "# fontScale\n",
        "fontScale = 1\n",
        "# Blue color in BGR\n",
        "color = (255, 0, 0)\n",
        "# Line thickness of 2 px\n",
        "thickness = 2\n",
        "\n",
        "  \n",
        "# define a video capture object\n",
        "vid = cv2.VideoCapture('')\n",
        "  \n",
        "while(True):\n",
        "      \n",
        "    # Capture the video frame\n",
        "    # by frame\n",
        "    #ret, frame = vid.read()\n",
        "    frame=cv2.imread(\"./rl1.PNG\")\n",
        "\n",
        "    if(frame.all() != None):\n",
        "\n",
        "      geteye=eyedetect.detectMultiScale(frame)\n",
        "      \n",
        "      eyes=[]\n",
        "      for (x,y,w,h) in geteye:\n",
        "          eyes.append(rgb[y:y+h, x:x+w])\n",
        "      \n",
        "      imageio.imshow(eyes[0])    \n",
        "      img = eyes[0]\n",
        "      img = Image.fromarray(img.astype('uint8'), 'RGB')\n",
        "      img = transform(img);\n",
        "      img = img[None]\n",
        "      scores = model(img)\n",
        "\n",
        "      print(scores)\n",
        "      prediction = scores[0].argmax()\n",
        "\n",
        "      frame = cv2.putText(frame, str(prediction), org, font, fontScale, color, thickness, cv2.LINE_AA)    \n",
        "    \n",
        "    #cv2.imshow('frame', frame)\n",
        "    cv2_imshow(frame);\n",
        "      \n",
        "    break;\n",
        "    # the 'q' button is set as the\n",
        "    # quitting button you may use any\n",
        "    # desired button of your choice\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "  \n",
        "# After the loop release the cap object\n",
        "vid.release()\n",
        "# Destroy all the windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "cFLKmz7leB9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kAirXH8AnmDv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "beatian.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}